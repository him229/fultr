{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.loadtxt('../GermanCredit/prod/german.data', dtype='str')\n",
    "new_data = np.zeros((1000,70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(attr, start, count):\n",
    "    return ['{}{}'.format(attr, i) for i in range(start, count+1)]\n",
    "\n",
    "a1 = foo('A1',1,4)\n",
    "a2 = [1]\n",
    "a3 = foo('A3',0,4)\n",
    "a4 = foo('A4',0,10)\n",
    "a5 = [4]\n",
    "a6 = foo('A6',1,5)\n",
    "a7 = foo('A7',1,5)\n",
    "a8 = [7]\n",
    "a9 = foo('A9',1,5)\n",
    "a10 = foo('A10',1,3)\n",
    "a11 = [10]\n",
    "a12 = foo('A12',1,4)\n",
    "a13 = [12]\n",
    "a14 = foo('A14',1,3)\n",
    "a15 = foo('A15',1,3)\n",
    "a16 = [15]\n",
    "a17 = foo('A17',1,4)\n",
    "a18 = [17]\n",
    "a19 = foo('A19',1,2)\n",
    "a20 = foo('A20',1,2)\n",
    "\n",
    "headers = a1 +a2 +a3 +a4 +a5 +a6 +a7 +a8 +a9 +a10+a11+a12+a13+a14+a15+a16+a17+a18+a19+a20\n",
    "len(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,h in enumerate(headers):\n",
    "    if not isinstance(h, int):\n",
    "        new_data[:,i][np.where(a == h)[0]] = 1.\n",
    "    else:\n",
    "        new_data[:,i] = a[:,h].astype(float)\n",
    "        \n",
    "# columns to be deleted        \n",
    "del_list = []\n",
    "for i in range(new_data.shape[1]):\n",
    "    if np.sum(new_data[:,i]) == 0:\n",
    "        del_list.append(i)\n",
    "delete_cols =  set(list(range(33,38)) + del_list[:-1]) #delete the colums for gender and unused ones, keep one for rels\n",
    "delete_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_del = []\n",
    "for i in delete_cols:\n",
    "    if i<len(headers):\n",
    "        headers_del.append(i)\n",
    "        print(headers[i])\n",
    "headers_ = []\n",
    "for i,h in enumerate(headers):\n",
    "    if i not in headers_del:\n",
    "        headers_.append(headers[i])\n",
    "headers_.insert(4,\"A9_Gender\")\n",
    "headers_.append(\"RELEVANCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "males = np.concatenate((np.where(a == 'A91')[0], np.where(a == 'A93')[0], np.where(a == 'A94')[0]))\n",
    "females = np.where(a == 'A92')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_del = np.delete(new_data, list(delete_cols), 1)\n",
    "#add gender in the 4th column\n",
    "new_data_ins = np.insert(new_data_del,4,np.zeros(1000),axis=1)\n",
    "new_data_ins[:,4][males]=1\n",
    "#add relevances in the last column\n",
    "new_data_ins[:,-1][a[:,-1].astype(float)==1]=1.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### ALTERNATE group feature\n",
    "### bad credit\n",
    "# g1 = np.concatenate((np.where(a == 'A30')[0], np.where(a == 'A31')[0], np.where(a == 'A32')[0]))\n",
    "# g0 = np.concatenate((np.where(a == 'A33')[0], np.where(a == 'A34')[0]))\n",
    "# group_col_num, other_del_cols = 6, [7,8,9,10]\n",
    "\n",
    "### car purpose\n",
    "g1 = np.concatenate((np.where(a == 'A42')[0], np.where(a == 'A43')[0], np.where(a == 'A44')[0],\n",
    "                    np.where(a == 'A45')[0], np.where(a == 'A46')[0], np.where(a == 'A47')[0],\n",
    "                    np.where(a == 'A48')[0], np.where(a == 'A49')[0], np.where(a == 'A410')[0]))\n",
    "g0 = np.concatenate((np.where(a == 'A40')[0], np.where(a == 'A41')[0]))\n",
    "group_col_num, other_del_cols = 11, [12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "assert len(g1) + len(g0) == new_data_ins.shape[0]\n",
    "len(g1), len(g0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_data_ins_del = np.delete(new_data_ins, other_del_cols, 1)\n",
    "new_data_ins_del[:,group_col_num][g0] = 0\n",
    "new_data_ins_del[:,group_col_num][g1] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "assert np.sum(new_data_ins_del[:,group_col_num]) == len(g1)\n",
    "new_data_ins_del.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Changed the categorical features to binary and the group column is 11\n",
    "np.savetxt('GermanCredit/prod/german_mod_car_11.data', new_data_ins_del, fmt='%-2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('../GermanCredit/prod/german_mod.data')\n",
    "data_ = RobustScaler(with_centering=False).fit_transform(data)\n",
    "group_column_number = 14\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonzero(vals):\n",
    "    return np.nonzero(vals)[0]\n",
    "\n",
    "def get_train_test_splits(idxs):\n",
    "    count_tr = int(len(idxs) * 0.35)\n",
    "    count_va = int(len(idxs) * 0.35) + count_tr\n",
    "    rand_idxs = np.random.rand(idxs.shape[0]).argsort()\n",
    "    train_idxs = idxs[rand_idxs[:count_tr]]\n",
    "    val_idxs = idxs[rand_idxs[count_tr:count_va]]\n",
    "    test_idxs = idxs[rand_idxs[count_va:]]\n",
    "    return train_idxs, val_idxs, test_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking_rel(t_p, t_n, rel_ratio, non_rel_ratio):\n",
    "    data_rel = data_[np.random.choice(t_p, rel_ratio, replace=False)]\n",
    "    data_non_rel = data_[np.random.choice(t_n, non_rel_ratio, replace=False)]\n",
    "    ranking = np.vstack([data_rel, data_non_rel])\n",
    "    rand_idxs = np.random.rand(ranking.shape[0]).argsort()\n",
    "    return ranking[rand_idxs][:,:-1], ranking[rand_idxs][:,-1]\n",
    "\n",
    "def get_final_rankings(num_queries_tr, num_queries_va, num_queries_te, rel_ratio, split, save=False):\n",
    "    non_rel_ratio = 20 - 2*rel_ratio\n",
    "    train_rankings = []\n",
    "    train_rels = []\n",
    "    test_rankings = []\n",
    "    test_rels = []\n",
    "    val_rankings = []\n",
    "    val_rels = []\n",
    "    \n",
    "    rels = data[:,-1]\n",
    "    \n",
    "    if group_column_number:\n",
    "        #TODO - deal with validation set\n",
    "        gender = data[:,group_column_number]\n",
    "        l = []\n",
    "        for g in [0.,1.]:\n",
    "            for r in [0.,1.]:\n",
    "                l.append(get_nonzero(np.logical_and(gender==g, rels==r)))\n",
    "        gen_f_rel_n, gen_f_rel_p, gen_m_rel_n, gen_m_rel_p = l\n",
    "\n",
    "        tr_gen_f_rel_n, va_gen_f_rel_n, te_gen_f_rel_n = get_train_test_splits(gen_f_rel_n)\n",
    "        tr_gen_f_rel_p, va_gen_f_rel_p, te_gen_f_rel_p = get_train_test_splits(gen_f_rel_p)\n",
    "        tr_gen_m_rel_n, va_gen_m_rel_n, te_gen_m_rel_n = get_train_test_splits(gen_m_rel_n)\n",
    "        tr_gen_m_rel_p, va_gen_m_rel_p, te_gen_m_rel_p = get_train_test_splits(gen_m_rel_p)\n",
    "\n",
    "        tr_p, va_p, te_p = np.hstack([tr_gen_m_rel_p, tr_gen_f_rel_p]), np.hstack(\n",
    "            [va_gen_f_rel_p, va_gen_m_rel_p]), np.hstack([te_gen_m_rel_p, te_gen_f_rel_p])\n",
    "        tr_n, va_n, te_n = np.hstack([tr_gen_m_rel_n, tr_gen_f_rel_n]), np.hstack(\n",
    "            [va_gen_f_rel_n, va_gen_m_rel_n]), np.hstack([te_gen_m_rel_n, te_gen_f_rel_n])\n",
    "    else:\n",
    "        data_p = np.nonzero(rels==1.)[0]\n",
    "        data_n = np.nonzero(rels==0.)[0]\n",
    "\n",
    "        tr_p, va_p, te_p = get_train_test_splits(data_p)\n",
    "        tr_n, va_n, te_n = get_train_test_splits(data_n)\n",
    "            \n",
    "    for i in range(num_queries_tr):\n",
    "        ranking_train, rel_train = get_ranking_rel(tr_p, tr_n, rel_ratio, non_rel_ratio)\n",
    "        train_rankings.append(ranking_train)\n",
    "        train_rels.append(rel_train)\n",
    "    for i in range(num_queries_te):\n",
    "        ranking_test, rel_test = get_ranking_rel(te_p, te_n, rel_ratio, non_rel_ratio)\n",
    "        test_rankings.append(ranking_test)\n",
    "        test_rels.append(rel_test)\n",
    "    for i in range(num_queries_va):\n",
    "        ranking_val, rel_val = get_ranking_rel(va_p, va_n, rel_ratio, non_rel_ratio)\n",
    "        val_rankings.append(ranking_val)\n",
    "        val_rels.append(rel_val)\n",
    "        \n",
    "    train_set = (train_rankings, train_rels)\n",
    "    test_set = (test_rankings, test_rels)\n",
    "    val_set = (val_rankings, val_rels)\n",
    "    if save:        \n",
    "        dir_name = \"../GermanCredit/prod/35:35:30_group{}_double/split{}/\".format(group_column_number, split)\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "        base_str = dir_name + \"relevance_german_mod_full\"\n",
    "        pkl.dump(train_set, open('{}_train_{}_{}:{}_split{}.pkl'.format(\n",
    "            base_str,num_queries_tr, rel_ratio, non_rel_ratio,split), 'wb'))\n",
    "        pkl.dump(test_set, open('{}_test_{}_{}:{}_split{}.pkl'.format(\n",
    "            base_str, num_queries_te, rel_ratio, non_rel_ratio,split), 'wb'))\n",
    "        pkl.dump(val_set, open('{}_val_{}_{}:{}_split{}.pkl'.format(\n",
    "            base_str, num_queries_va, rel_ratio, non_rel_ratio, split), 'wb'))\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    get_final_rankings(500, 500, 500, 1,i, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
