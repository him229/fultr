{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import copy\n",
    "\n",
    "# from models import LinearModel, convert_vars_to_gpu\n",
    "from utils import logsumexp, parse_my_args_reinforce, shuffle_combined, torchify, exp_lr_scheduler, get_optimizer\n",
    "\n",
    "# from models import LinearModel\n",
    "from torch.autograd import Variable\n",
    "from datareader import reader_from_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    \"\"\"\n",
    "    One layer simple linear model\n",
    "    \"\"\"\n",
    "    def __init__(self, D=2, clamp=False):\n",
    "        self.input_dim = D\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.w = nn.Linear(D, 1, bias=True)\n",
    "        self.w.weight.data.uniform_(-0.0000001, 0.0000001)\n",
    "        self.clamp = clamp\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.w(x)\n",
    "        return h if not self.clamp else torch.clamp(h, -10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0364],\n",
      "        [0.0364],\n",
      "        [0.0364],\n",
      "        [0.0364],\n",
      "        [0.0364],\n",
      "        [0.0364],\n",
      "        [0.0364],\n",
      "        [0.0364],\n",
      "        [0.0364],\n",
      "        [0.0364]], grad_fn=<ThAddmmBackward>)\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000], grad_fn=<AsStridedBackward>)\n"
     ]
    }
   ],
   "source": [
    "data_reader, validation_data_reader = reader_from_pickle(\n",
    "    \"GermanCredit/partial_german_train_rank_weightedclick_10k_old.pkl\"), reader_from_pickle(\n",
    "    \"GermanCredit/partial_german_test_rank_weightedclick_10k_old.pkl\")\n",
    "\n",
    "train_feats, train_rel = data_reader.data\n",
    "train_feats, train_rel = torch.FloatTensor(train_feats), torch.FloatTensor(train_rel)\n",
    "train_feats, train_rel = shuffle_combined(train_feats, train_rel)\n",
    "\n",
    "model = LinearModel(D=29)\n",
    "\n",
    "feats,rels = train_feats[530], train_rel[530]\n",
    "scores = model(Variable(feats))\n",
    "print(scores)\n",
    "probs = torch.nn.Softmax(dim=0)(scores).flatten()\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores tensor([[0.1189],\n",
      "        [0.1189],\n",
      "        [0.1189],\n",
      "        [0.1189],\n",
      "        [0.1188],\n",
      "        [0.1189],\n",
      "        [0.1190],\n",
      "        [0.1188],\n",
      "        [0.1186],\n",
      "        [0.1188]], grad_fn=<ThAddmmBackward>)\n",
      "scores_ tensor([[0.1001],\n",
      "        [0.1000],\n",
      "        [0.1001],\n",
      "        [0.1000],\n",
      "        [0.1000],\n",
      "        [0.1001],\n",
      "        [0.1001],\n",
      "        [0.1000],\n",
      "        [0.0998],\n",
      "        [0.1000]], grad_fn=<DivBackward1>)\n",
      "probs tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000], grad_fn=<AsStridedBackward>)\n",
      "probs_ tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000], grad_fn=<AsStridedBackward>)\n",
      "torch.Size([10, 58]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel(D=58)\n",
    "data_reader, validation_data_reader = reader_from_pickle(\n",
    "    \"GermanCredit/partial_german_train_rank_weightedclick_10k.pkl\"), reader_from_pickle(\n",
    "    \"GermanCredit/partial_german_test_rank_weightedclick_10k.pkl\")\n",
    "train_feats, train_rel = data_reader.data\n",
    "train_feats, train_rel = torch.FloatTensor(train_feats), torch.FloatTensor(train_rel)\n",
    "train_feats, train_rel = shuffle_combined(train_feats, train_rel)\n",
    "feats,rels = train_feats[0], train_rel[0]\n",
    "scores = model(Variable(feats))\n",
    "print(\"scores\", scores)\n",
    "scores_ = scores/scores.sum()\n",
    "print(\"scores_\", scores_)\n",
    "probs = torch.nn.Softmax(dim=0)(scores).flatten()\n",
    "print(\"probs\", probs)\n",
    "probs_ = torch.nn.Softmax(dim=0)(scores_).flatten()\n",
    "print(\"probs_\", probs_)\n",
    "print(feats.shape, rels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import compute_dcg, evaluate_model, sample_ranking, compute_average_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings, rewards_list, ndcg_list, dcg_list = [], [], [], []\n",
    "for j in range(5):\n",
    "    ranking = sample_ranking(probs, False)\n",
    "    rankings.append(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rels = torch.tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0.])\n",
    "rankings, rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_identities = feats[:, 3]\n",
    "t_rankings = torch.stack(rankings)\n",
    "rankings, skip_zero,rel = t_rankings, True, rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import get_exposures\n",
    "position_bias_vector = 1./torch.arange(1.,11.)\n",
    "get_exposures(ranking, position_bias_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs =10\n",
    "position_bias_vector[:num_docs].unsqueeze(0).repeat(rankings.shape[0],1)\n",
    "position_biases = position_bias_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposures = torch.stack([get_exposures(ranking, position_biases) for i in rankings])\n",
    "inds_g0 = group_identities == 0\n",
    "inds_g1 = group_identities == 1\n",
    "if skip_zero:\n",
    "    inds_g0 = inds_g0 * (rel != 0)\n",
    "    inds_g1 = inds_g1 * (rel != 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_g0 * (rel != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exposures(ranking, position_bias_vector):\n",
    "    num_docs = len(ranking)\n",
    "    exposure = np.zeros(num_docs)\n",
    "    exposure[ranking] = position_bias_vector[:num_docs]\n",
    "    return exposure\n",
    "\n",
    "def compute_group_disparity(ranking,\n",
    "                            rel,\n",
    "                            group_identities,\n",
    "                            position_biases,\n",
    "                            skip_zero=False):\n",
    "    exposures = get_exposures(ranking, position_biases)\n",
    "    inds_g0 = group_identities == 0\n",
    "    inds_g1 = group_identities == 1\n",
    "    if skip_zero:\n",
    "        inds_g0 = np.logical_and(inds_g0, rel != 0)\n",
    "        inds_g1 = np.logical_and(inds_g1, rel != 0)\n",
    "    return np.sum(exposures[inds_g0]) / np.sum(rel[inds_g0]) - np.sum(\n",
    "        exposures[inds_g1]) / np.sum(rel[inds_g1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_group_disparity(rankings[4].numpy(), rels.numpy(), group_identities.numpy(), position_bias_vector.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exposures(ranking, position_bias_vector):\n",
    "    num_docs = len(ranking)\n",
    "    exposure = torch.zeros(num_docs)\n",
    "    exposure[ranking] = position_bias_vector[:num_docs]\n",
    "    return exposure\n",
    "\n",
    "def compute_group_disparity(ranking,\n",
    "                            rel,\n",
    "                            group_identities,\n",
    "                            position_biases,\n",
    "                            skip_zero=False):\n",
    "    exposures = get_exposures(ranking, position_biases)\n",
    "    inds_g0 = group_identities == 0\n",
    "    inds_g1 = group_identities == 1\n",
    "    if skip_zero:\n",
    "        inds_g0 = inds_g0 * (rel != 0)\n",
    "        inds_g1 = inds_g1 * (rel != 0)\n",
    "    return torch.sum(exposures[inds_g0]) / torch.sum(rel[inds_g0]) - torch.sum(\n",
    "        exposures[inds_g1]) / torch.sum(rel[inds_g1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_group_disparity(rankings[0], rels, group_identities, position_bias_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings_, rels_, group_identities_, position_bias_vector_ = rankings[4].numpy(), rels.numpy(), group_identities.numpy(), position_bias_vector.numpy()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "exposures = get_exposures(rankings_, position_bias_vector_)\n",
    "inds_g0 = group_identities == 0\n",
    "inds_g1 = group_identities == 1\n",
    "inds_g0, inds_g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import compute_log_model_probability\n",
    "from utils import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_model_probability(scores, rankings[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtracts = torch.zeros_like(scores)\n",
    "log_probs = torch.zeros_like(scores)\n",
    "# if gpu:\n",
    "#     subtracts, log_probs = convert_vars_to_gpu([subtracts, log_probs])\n",
    "for j in range(scores.size()[0]):\n",
    "    posj = ranking[j]\n",
    "    log_probs[j] = scores[posj] - logsumexp(scores - subtracts, dim=0)\n",
    "    subtracts[posj] = scores[posj] + 1e6\n",
    "torch.sum(log_probs)\n",
    "# log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores, ranking\n",
    "print(probs)\n",
    "log_probs = torch.zeros_like(probs)\n",
    "for posj in ranking:\n",
    "    log_probs[posj] = torch.log(probs)[posj]\n",
    "    probs[posj] = 0\n",
    "    probs = torch.nn.functional.softmax(probs)\n",
    "    print(probs)\n",
    "torch.sum(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores, ranking\n",
    "print(scores)\n",
    "scores_= scores\n",
    "log_probs = torch.zeros_like(scores_)\n",
    "print(torch.nn.functional.log_softmax(scores_, dim=0))\n",
    "for posj in ranking:\n",
    "    log_probs[posj] = torch.nn.functional.log_softmax(scores_, dim=0)[posj]\n",
    "    scores_[posj] = -1e6\n",
    "torch.sum(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtracts = torch.zeros_like(scores)\n",
    "log_probs = torch.zeros_like(scores)\n",
    "# subtracts[ranking] = scores[ranking] + 1e6\n",
    "for j in range(len(ranking)):\n",
    "    log_probs[j] = scores[j] - logsumexp(scores - subtracts, dim=0)\n",
    "    subtracts[j] = scores[j] + 1e6\n",
    "#     print(logsumexp(scores - subtracts, dim=0))\n",
    "# print(log_probs, ranking)\n",
    "torch.sum(log_probs)\n",
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.log_softmax(scores,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtracts = torch.zeros_like(scores)\n",
    "log_probs = torch.zeros_like(scores)\n",
    "# if gpu:\n",
    "#     subtracts, log_probs = convert_vars_to_gpu([subtracts, log_probs])\n",
    "# for j in range(scores.size()[0]):\n",
    "j=torch.arange(scores.size()[0])\n",
    "posj = ranking[j]\n",
    "subtracts[posj] = scores[posj] + 1e6\n",
    "log_probs[j] = scores[posj] - logsumexp(scores - subtracts, dim=0)\n",
    "torch.sum(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = [0.6770715117454529,\n",
    "0.6976408958435059,\n",
    "0.7047403454780579,\n",
    "0.7139430642127991,\n",
    "0.7054921388626099,\n",
    "0.6972674131393433,\n",
    "0.7208537459373474,\n",
    "0.71114182472229,\n",
    "0.7081214785575867,\n",
    "0.6965669393539429]\n",
    "ndcgs = [0.6770715117454529,\n",
    "0.6976408958435059,\n",
    "0.7047403454780579,\n",
    "0.7139430642127991,\n",
    "0.7054921388626099,\n",
    "0.6972674131393433,\n",
    "0.7208537459373474,\n",
    "0.71114182472229,\n",
    "0.7081214785575867,\n",
    "0.6965669393539429]\n",
    "dcgs = [47.724464416503906,\n",
    "53.05571365356445,\n",
    "56.91681671142578,\n",
    "58.481204986572266,\n",
    "56.369693756103516,\n",
    "56.18364715576172,\n",
    "51.54362106323242,\n",
    "62.39633560180664,\n",
    "61.6878662109375,\n",
    "57.674381256103516]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot([i for i in range(5000,100000,10000)], ndcgs, label='NDCGs')\n",
    "legend = plt.legend()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('NDCG')\n",
    "\n",
    "plt.plot([i for i in range(5000,100000,10000)], [dcg/100. for dcg in dcgs], label='DCGs')\n",
    "legend = plt.legend()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('DCG')\n",
    "\n",
    "plt.savefig('fig.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sort(-probs)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e-6 == .000005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"1e-5\")+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
