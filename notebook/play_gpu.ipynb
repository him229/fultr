{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import copy\n",
    "\n",
    "from models import LinearModel, convert_vars_to_gpu\n",
    "from utils import logsumexp, shuffle_combined, torchify, exp_lr_scheduler, get_optimizer\n",
    "from datareader import reader_from_pickle, DataReader\n",
    "from args import args\n",
    "from evaluation import sample_ranking, compute_dcg_rankings, compute_dcg, compute_average_rank, sample_multiple_ranking\n",
    "from fairness_loss import get_exposures, get_multiple_exposures, GroupFairnessLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11974, 4009, 4065)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trdr, vadr, tedr = reader_from_pickle(\n",
    "    \"../GermanCredit/MSLR_Fold1/full/train.pkl\"), reader_from_pickle(\n",
    "    \"../GermanCredit/MSLR_Fold1/full/valid.pkl\"), reader_from_pickle(\n",
    "    \"../GermanCredit/MSLR_Fold1/full/test.pkl\")\n",
    "tr,va, te = list(trdr.data), list(vadr.data), list(tedr.data)\n",
    "len(tr[0]), len(va[0]), len(te[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "zero_clicks = []\n",
    "data_reader, validation_data_reader = reader_from_pickle(\"GermanCredit/partial_german_train_rank_weightedclick_10k.pkl\"), reader_from_pickle(\"GermanCredit/partial_german_test_rank_weightedclick_10k.pkl\")\n",
    "tr, te = list(data_reader.data), list(validation_data_reader.data)\n",
    "\n",
    "for i,row in enumerate(data_reader.data[1]):\n",
    "    if np.sum(row) == 0:\n",
    "        zero_clicks.append(i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(zero_clicks)/30000"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zero_clicks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_reader.data[1][5400]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_single_sample(i):\n",
    "    a = [tr[0][i]]\n",
    "    b = [tr[1][i]]\n",
    "    dr = DataReader()\n",
    "    dr.data = (a,b)\n",
    "    c = (torch.cuda.FloatTensor(a),torch.cuda.FloatTensor(b))\n",
    "    return dr,c"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from models import LinearModel\n",
    "from torch.autograd import Variable\n",
    "model = LinearModel(D=29).cuda()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def foo_dcg(ran,rels):\n",
    "    return compute_dcg(torch.cuda.LongTensor(ran), torch.cuda.FloatTensor(rels))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "foo_dcg([0, 1, 2, 3], [1,1,0,1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from generate_dataset import rel_to_click, prop_weighted_click\n",
    "temp=0.0\n",
    "for i in range(500):\n",
    "    clicks = prop_weighted_click(rel_to_click([1,1,0,1]))\n",
    "    temp+=foo_dcg([0,1,2,3], clicks)[1]\n",
    "temp/500\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c = get_single_sample(8787)[1]\n",
    "# print(c)\n",
    "feats,rel = c[0],c[1]\n",
    "scores = model(Variable(feats))\n",
    "probs_ = torch.nn.Softmax(dim=1)(scores)\n",
    "# probs = probs_.flatten()\n",
    "probs=torch.tensor([0.1000, 0.1000, 0.7000, 0.1000, 0.1000, 0.9000, 0.1000, 0.1000, 0.1000,\n",
    "         0.1000])\n",
    "rankings = [sample_ranking(probs, False) for _ in range(10)]\n",
    "t_rankings = torch.stack(rankings)\n",
    "t_rankings, probs\n",
    "# for j in range(10):\n",
    "#     ranking = sample_ranking(probs, False)\n",
    "#     ndcg, dcg = compute_dcg(ranking, rel, 1000)\n",
    "#     print(ndcg, dcg)\n",
    "#     av_ranks = compute_average_rank(ranking, rel)\n",
    "#     err = compute_err(ranking, rel)\n",
    "#     curr_ndcg_list.append(ndcg)\n",
    "#     curr_dcg_list.append(dcg)\n",
    "#     relevant_rank_list.extend(av_ranks)\n",
    "#     curr_err_list.append(err)\n",
    "#     if fairness_evaluation or group_fairness_evaluation:\n",
    "#         curr_exposure = get_exposures(ranking, position_bias_vector).cuda()\n",
    "#         exposures += curr_exposure"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wvdr = reader_from_pickle(\"GermanCredit/partial_german_train_rank_weightedclick_10k.pkl\")\n",
    "len(wvdr.data[0])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from evaluation import evaluate_model\n",
    "dr = get_single_sample(673)[0]\n",
    "evaluate_model(model,dr, gpu=True, args=args)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datareader import DataReader, reader_from_pickle\n",
    "import numpy as np\n",
    "\n",
    "def reduce_to_two_samples(data_r):\n",
    "    fe, re = data_r.data[0], data_r.data[1]\n",
    "    a = [fe[0], fe[1]]\n",
    "    b = [re[0], re[1]]\n",
    "    return (a,b)\n",
    "\n",
    "dr = reader_from_pickle(\"GermanCredit/german_train_rank.pkl\")\n",
    "vdr = reader_from_pickle(\"GermanCredit/german_test_rank.pkl\")\n",
    "wdr = reader_from_pickle(\"GermanCredit/partial_german_train_rank_weightedclick_10k.pkl\")\n",
    "wvdr = reader_from_pickle(\"GermanCredit/partial_german_test_rank_weightedclick_10k.pkl\")\n",
    "\n",
    "dc = DataReader()\n",
    "vdc = DataReader()\n",
    "wdc = DataReader()\n",
    "wvdc = DataReader()\n",
    "\n",
    "dc.data = reduce_to_two_samples(dr)\n",
    "vdc.data = reduce_to_two_samples(vdr)\n",
    "wdc.data = reduce_to_two_samples(wdr)\n",
    "wvdc.data = reduce_to_two_samples(wvdr)\n",
    "\n",
    "dc.pickelize_data(outpath=\"GermanCredit/single/german_train_rank.pkl\")\n",
    "vdc.pickelize_data(outpath=\"GermanCredit/single/german_test_rank.pkl\")\n",
    "wdc.pickelize_data(outpath=\"GermanCredit/single/partial_german_train_rank_weightedclick_10k.pkl\")\n",
    "wvdc.pickelize_data(outpath=\"GermanCredit/single/partial_german_test_rank_weightedclick_10k.pkl\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type(reduce_to_two_samples(wvdr)[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dr = reader_from_pickle(\"GermanCredit/german_train_rank.pkl\")\n",
    "type(dr.data[0][6])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fe,re = reader_from_pickle(\"GermanCredit/partial_german_train_rank_weightedclick_10k.pkl\").data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fe[1], re[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from evaluation import compute_dcg\n",
    "compute_dcg(torch.tensor(fe[1]).cuda(), torch.tensor(re[1]).cuda())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1/torch.log2(torch.arange(4.)+2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ranking = torch.arange(10.)+1\n",
    "rels = torch.FloatTensor(re[1])\n",
    "ranking.type()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hello = torch.LongTensor([1,3,4])\n",
    "print(hello.type())\n",
    "relevance = torch.LongTensor([9,6,5,4,3,2])\n",
    "print(relevance[hello])\n",
    "\n",
    "long = torch.LongTensor([1,2,3])\n",
    "long.type()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "def compute_dcg2(ranking, relevance_vector, k=None):\n",
    "    dcgmax = 0.0\n",
    "    dcg = 0.0\n",
    "    N = len(relevance_vector)\n",
    "    if k is None:\n",
    "        k=N\n",
    "    ranking = ranking[:min((k, N))]\n",
    "    len_ranking = float(len(ranking))\n",
    "#     import pdb; pdb.set_trace()\n",
    "    sorted_relevances = -torch.sort(-relevance_vector)[0][:min((k, N))]\n",
    "    len_sorted_relevances = float(len(sorted_relevances))\n",
    "\n",
    "    dcgmax = torch.sum(sorted_relevances / torch.log2(torch.arange(len_sorted_relevances)+2))\n",
    "    dcg = torch.sum(relevance_vector[ranking] / torch.log2(torch.arange(len_ranking)+2).cuda())\n",
    "    if dcgmax == 0: dcgmax = 1.0\n",
    "    return dcg / dcgmax, dcg"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "compute_dcg2(ranking,rels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from generate_dataset import get_sampled_train_datasets, get_sampled_validations_datasets\n",
    "from datareader import DataReader, reader_from_pickle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vdr = reader_from_pickle(\"GermanCredit/german_test_rank.pkl\")\n",
    "num_samples_val = [500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000]\n",
    "for i in num_samples_val:\n",
    "    dr = get_sampled_validations_datasets(vdr, num_samples_val=i, save=True)\n",
    "    print(len(dr.data[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vdr = reader_from_pickle(\"GermanCredit/german_train_rank.pkl\")\n",
    "num_samples_val = [500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000]\n",
    "for i in num_samples_val:\n",
    "    dr = get_sampled_train_datasets(vdr, num_samples=i, save=True)\n",
    "    print(len(dr.data[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "from models import LinearModel\n",
    "from evaluation import evaluate_model\n",
    "from args import args"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vdc = reader_from_pickle(\"GermanCredit/validations/partial_validations_500.pkl\")\n",
    "model = torch.load(\n",
    "    \"models/gf_lambda0.0/partial_try17_lr01_decay04_dcgchange_fix_reward_good_lambda0.0_epoch37.ckpt\").cuda()\n",
    "results = evaluate_model(model, vdc, fairness_evaluation=False, group_fairness_evaluation=True, \n",
    "                                 deterministic=False, gpu=True, args=args, num_sample_per_query=20)\n",
    "[results[\"dcg\"], results[\"avg_group_asym_disparity\"]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vdc = reader_from_pickle(\"GermanCredit/german_test_rank.pkl\")\n",
    "model = torch.load(\n",
    "    \"models/gf_lambda0.0/partial_try17_lr01_decay04_dcgchange_fix_reward_good_lambda0.0_epoch37.ckpt\").cuda()\n",
    "results = evaluate_model(model, vdc, fairness_evaluation=False, group_fairness_evaluation=True, \n",
    "                                 deterministic=False, gpu=True, args=args, num_sample_per_query=20)\n",
    "[results[\"dcg\"], results[\"avg_group_asym_disparity\"]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "vals = []\n",
    "for n in [500, 1000, 5000, 10000, 50000, 100000, 500000]:\n",
    "    name_k = \"{}k\".format(int(n/1000.0)) if n>=1000.0 else \"{}\".format(int(n))\n",
    "    vals.append(round(np.loadtxt(\n",
    "        \"GermanCredit/validations/data/pl_gf_lambda_0.0__size_{}.out\".format(name_k), delimiter=',')[0], 5))\n",
    "vals"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(vals, color='red')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datareader import DataReader, reader_from_pickle\n",
    "dc = reader_from_pickle(\"GermanCredit/prod/ranked_train.pkl\")\n",
    "vdc = reader_from_pickle(\"GermanCredit/prod/ranked_test.pkl\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = set()\n",
    "for i in range(500):\n",
    "    for j in range(10):\n",
    "        a.add(tuple(list(dc.data[0][i][j]) + [dc.data[1][i][j]]))\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b = set()\n",
    "for i in range(100):\n",
    "    for j in range(10):\n",
    "        b.add(tuple(list(vdc.data[0][i][j]) + [vdc.data[1][i][j]]))\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cb = 0.\n",
    "ca = 0.\n",
    "for e in b:\n",
    "    cb += e[29]\n",
    "for e in a:\n",
    "    ca += e[29]\n",
    "ca,cb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dc.data[0].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "a = torch.tensor([[  6.9913],\n",
    "        [116.8210],\n",
    "        [112.0555],\n",
    "        [ 37.1170],\n",
    "        [103.8954],\n",
    "        [ 21.6164],\n",
    "        [ 26.6666],\n",
    "        [129.3001],\n",
    "        [ 62.9670],\n",
    "        [ 11.6055]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"a\",a)\n",
    "print(\"a/sum\",a/a.sum())\n",
    "print(\"bn\",torch.nn.BatchNorm1d(num_features=1)(a))\n",
    "torch.nn.Softmax(dim=0)(torch.nn.BatchNorm1d(num_features=1)(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=torch.tensor([0.1000, 0.1000, 0.7000, 0.1000, 0.1000, 0.9000, 0.1000, 0.1000, 0.1000,\n",
    "         0.1000])\n",
    "position_bias_vector = 1/torch.arange(1.,11.)\n",
    "rankings = sample_multiple_ranking(probs, 5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num_docs = rankings.shape[1]\n",
    "exposures = torch.zeros_like(rankings).float()\n",
    "position_bias_matrix = position_bias_vector[:num_docs].expand_as(rankings)\n",
    "batch_index = torch.arange(rankings.shape[0])\n",
    "for i in range(rankings.shape[0]):\n",
    "    exposures[i][rankings[i]] = position_bias_matrix[i]\n",
    "exposures\n",
    "# exposures[batch_index, rankings] = position_bias_matrix\n",
    "# exposures.type()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pb_matrix = position_bias_vector[:10].expand_as(rankings)\n",
    "# torch.gather(pb_matrix, 0, rankings)\n",
    "exposures = torch.zeros_like(rankings).float()\n",
    "exposures.scatter_(1, rankings, pb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667, 0.2000, 1.0000, 0.5000, 0.1111, 0.3333, 0.1250, 0.2500, 0.1429,\n",
       "         0.1000],\n",
       "        [0.3333, 0.2000, 0.2500, 0.1429, 0.5000, 1.0000, 0.1000, 0.1111, 0.1667,\n",
       "         0.1250],\n",
       "        [0.1111, 0.1429, 1.0000, 0.2500, 0.1667, 0.5000, 0.1000, 0.2000, 0.1250,\n",
       "         0.3333],\n",
       "        [0.2000, 0.5000, 0.3333, 0.1111, 0.1250, 1.0000, 0.1429, 0.1000, 0.1667,\n",
       "         0.2500],\n",
       "        [0.3333, 0.1250, 1.0000, 0.1667, 0.1111, 0.5000, 0.1429, 0.1000, 0.2500,\n",
       "         0.2000]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_multiple_exposures(rankings.cuda(), 1/torch.arange(1.,11.).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1667, 0.2000, 1.0000, 0.5000, 0.1111, 0.3333, 0.1250, 0.2500, 0.1429,\n",
      "        0.1000])\n",
      "tensor([0.3333, 0.2000, 0.2500, 0.1429, 0.5000, 1.0000, 0.1000, 0.1111, 0.1667,\n",
      "        0.1250])\n",
      "tensor([0.1111, 0.1429, 1.0000, 0.2500, 0.1667, 0.5000, 0.1000, 0.2000, 0.1250,\n",
      "        0.3333])\n",
      "tensor([0.2000, 0.5000, 0.3333, 0.1111, 0.1250, 1.0000, 0.1429, 0.1000, 0.1667,\n",
      "        0.2500])\n",
      "tensor([0.3333, 0.1250, 1.0000, 0.1667, 0.1111, 0.5000, 0.1429, 0.1000, 0.2500,\n",
      "        0.2000])\n"
     ]
    }
   ],
   "source": [
    "for i in range(rankings.shape[0]):\n",
    "    print(get_exposures(rankings[i], 1/torch.arange(1.,11.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = reader_from_pickle(\"../GermanCredit/partial_german_train_rank_weightedclick_10k.pkl\")\n",
    "feats,rels = dr.data\n",
    "feats,rels = torch.FloatTensor(feats), torch.FloatTensor(rels)\n",
    "f,r = feats[41], rels[41]\n",
    "f,r = torch.FloatTensor(f), torch.FloatTensor(r)\n",
    "\n",
    "group_identities = f[:,13]\n",
    "a = 1 if r[group_identities == 0].mean() >= r[group_identities == 1].mean() else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_identities == 0, r\n",
    "rel = r"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "position_biases = 1/torch.arange(1.,11.)\n",
    "exposures = get_multiple_exposures(rankings, position_biases)\n",
    "inds_g0 = group_identities == 0\n",
    "inds_g1 = group_identities == 1\n",
    "g0_merit = torch.sum(rel[inds_g0])\n",
    "g1_merit = torch.sum(rel[inds_g1])\n",
    "exposures_g1 = exposures[inds_g1.unsqueeze(0).expand_as(rankings)].view(-1,len(rel[inds_g1]))\n",
    "exposures_g0 = exposures[inds_g0.unsqueeze(0).expand_as(rankings)].view(-1,len(rel[inds_g0]))\n",
    "g1_merit/torch.sum(exposures_g1, dim=1) - g0_merit/torch.sum(exposures_g0, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.FloatTensor([0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GroupFairnessLoss.compute_multiple_group_disparity(rankings.cuda(), rel, group_identities, 1/torch.arange(1.,11.).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "for i in range(rankings.shape[0]):\n",
    "    print(GroupFairnessLoss.compute_group_disparity(rankings[i], rel, group_identities, 1/torch.arange(1.,11.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LinearModel\n",
    "from torch.autograd import Variable\n",
    "model = LinearModel(D=58).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1207, device='cuda:0')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats= feats\n",
    "train_rel = rels\n",
    "sample_size = 10\n",
    "position_bias_vector = (1. / torch.arange(1., 100.)).cuda()\n",
    "len_train_set=len(train_feats)\n",
    "    \n",
    "group_disparity_indicator_batch_size = int(len_train_set/20)\n",
    "group_disp_feats = train_feats[torch.randperm(\n",
    "    train_feats.shape[0])[:group_disparity_indicator_batch_size]].cuda()\n",
    "group_disp_rels = train_rel[torch.randperm(\n",
    "    train_feats.shape[0])[:group_disparity_indicator_batch_size]].cuda()\n",
    "scores = model(Variable(group_disp_feats)).squeeze()\n",
    "probs = torch.nn.Softmax(dim=0)(scores)\n",
    "indicator_disparities = []\n",
    "\n",
    "for i in range(group_disparity_indicator_batch_size):\n",
    "    rankings = sample_multiple_ranking(probs[i], sample_size)\n",
    "    group_identities = group_disp_feats[i][:, args.group_feat_id]\n",
    "    indicator_disparities.append(GroupFairnessLoss.compute_multiple_group_disparity(\n",
    "    rankings, group_disp_rels[i], group_identities, position_bias_vector).mean())\n",
    "indicator_disparities = torch.stack(indicator_disparities)\n",
    "indicator_disparities.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.5072, -3.2102,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000, -1.2832,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         3.9912,  1.0180,  0.0000,  0.0000,  0.6887,  4.5148,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.8611,  0.3627,  1.5239,\n",
       "         0.0000,  0.0000,  0.3880,  0.3885,  0.0000,  0.0000,  1.0787,  0.0000,\n",
       "         3.0205,  0.0000,  0.0000,  0.6635,  0.0000,  0.0000,  0.0000,  2.4734,\n",
       "         0.0000,  0.5244, -1.2772], device='cuda:0')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator_disparities[0]\n",
    "indicator_disparities = torch.cat((indicator_disparities[450:], indicator_disparities[0].view(1)))\n",
    "indicator_disparities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1210], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator_disparities[9].view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(-probs[0])[1].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
