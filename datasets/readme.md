# Datasets

We use MSLR and German Credit Datasets for training. They can be found online using the links below:

`MSLR-WEB30K (Fold 1)` - <https://www.microsoft.com/en-us/research/project/mslr/>

`German Credit` - <https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)>

## Transformation

### German Credit Dataset

This dataset contains information about 1000 individuals which are randomly split into train, validation, and test sets with ratio 1:1:1. We convert this to an LTR dataset by sampling 20 individuals from the each set with ratio 9:1 for non-creditworthy individuals to creditworthy individuals for each query.

Group attribute - A binary feature indicating whether the purpose is radio/television (attribute id A43)

### MSLR

We adopt the train, validation, and test split provided with the dataset. We binarize relevances by assigning 1 to items that were judged as 3 or 4 and 0 to judgments 0, 1, and 2. Next, we remove queries with less than 20 candidates (to better compare different methods and amplify differences). For the remaining queries, we sample 20 candidate items with at most 3 relevant items for each query.

Group attribute - QualityScore (feature id 133) with 40th percentile as the threshold

## Click Data

We first train a conventional Ranking SVM with 1 percent of the full-information training data as the logging policy. This logging policy is then used to generate the rankings for which click data is logged.

The click data is generated by simulating the position-based examination model. We use a position bias that decays with the presented rank k of the item as `v(k) = (1/k)^n` with `n=1` as default. (file: `generate_clicks_for_dataset.py`)